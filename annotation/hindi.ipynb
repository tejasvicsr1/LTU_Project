{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-05 19:41:38 INFO: Loading these models for language: hi (Hindi):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | hdtb    |\n",
      "| pos       | hdtb    |\n",
      "| lemma     | hdtb    |\n",
      "| depparse  | hdtb    |\n",
      "=======================\n",
      "\n",
      "/home/tejasvi/anaconda3/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "2021-04-05 19:41:38 INFO: Use device: cpu\n",
      "2021-04-05 19:41:38 INFO: Loading: tokenize\n",
      "2021-04-05 19:41:38 INFO: Loading: pos\n",
      "2021-04-05 19:41:39 INFO: Loading: lemma\n",
      "2021-04-05 19:41:39 INFO: Loading: depparse\n",
      "2021-04-05 19:41:39 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import spacy\n",
    "from headers import *\n",
    "from helper_hindi import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hindata will store the corpus.\n",
    "# hintags will store the POS tags for all the words in a sentence for all the senteces in the corpus.\n",
    "# hintags = [{\"word_tags\": {\"word\": token, \"POS_TAG\": token.pos_}}] is the structure of engtags.\n",
    "hindata = []\n",
    "hintags = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the corpus\n",
    "f = open(\"../hin_conditional_sentences.txt\", 'r')\n",
    "for sentences in f:\n",
    "    sentences = sentences.rstrip()\n",
    "    hindata.append(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the POS tags of all the the words in a sentence for all sentences in the corpus.\n",
    "for sentence in hindata:\n",
    "    sentence = nlp_hi(sentence)\n",
    "    tagged_sentence = get_pos_tags(sentence, 1)\n",
    "    dep_sentence = get_dependencies(sentence, 1)\n",
    "    sentence_len = len(tagged_sentence[0])\n",
    "    bigtemp = {}\n",
    "    tokens = []\n",
    "    for i in range(sentence_len):\n",
    "        temp = {}\n",
    "        temp[\"word\"] = dep_sentence[0][i][1]\n",
    "        temp[\"POS_TAG\"] = tagged_sentence[0][i]\n",
    "        tokens.append(temp)\n",
    "    bigtemp[\"word_tags\"] = tokens\n",
    "    hintags.append(bigtemp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "501\n"
     ]
    }
   ],
   "source": [
    "# Printing the sentences along with the POS tags.\n",
    "g = open(\"data/hin_pos_tags.txt\", 'w')\n",
    "print_func(hintags, hindata, g)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
